import streamlit as st
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from langchain import LLMChain, PromptTemplate
from langchain_groq import ChatGroq
import os
import re
import json
from dotenv import load_dotenv
import matplotlib.pyplot as plt

load_dotenv()

# Configurar el modelo LLM
os.environ["GROQ_API_KEY"] = os.getenv("GROQ_API_KEY")
llm = ChatGroq(
    model="gemma2-9b-it",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)

noticias = [
    "Repsol, entre las 50 empresas que m谩s responsabilidad hist贸rica tienen en el calentamiento global",
    "Amancio Ortega crea un fondo de 100 millones de euros para los afectados de la dana",
    "Freshly Cosmetics despide a 52 empleados en Reus, el 18% de la plantilla",
    "Wall Street y los mercados globales caen ante la incertidumbre por la guerra comercial y el temor a una recesi贸n",
    "El mercado de criptomonedas se desploma: Bitcoin cae a 80.000 d贸lares, las altcoins se hunden en medio de una fren茅tica liquidaci贸n",
    "Granada retrasa seis meses el inicio de la Zona de Bajas Emisiones, previsto hasta ahora para abril",
    "McDonald's donar谩 a la Fundaci贸n Ronald McDonald todas las ganancias por ventas del Big Mac del 6 de diciembre",
    "El Gobierno autoriza a altos cargos p煤blicos a irse a Indra, Escribano, CEOE, Barcel贸, Iberdrola o Airbus",
    "Las aportaciones a los planes de pensiones caen 10.000 millones en los 煤ltimos cuatro a帽os",
]

preguntas_inversor = [
    "驴Cu谩l es tu objetivo principal al invertir?",
    "驴Cu谩l es tu horizonte temporal de inversi贸n?",
    "驴Tienes experiencia previa invirtiendo en activos de mayor riesgo como acciones, criptomonedas o fondos alternativos?",
    "驴Est谩s dispuesto a sacrificar parte de la rentabilidad potencial a cambio de un impacto social o ambiental positivo?",
    "驴Qu茅 opinas sobre el cambio clim谩tico?"
]

# Plantillas
plantilla_evaluacion = """
Eval煤a si esta respuesta del usuario es suficientemente detallada para un an谩lisis ESG. 
Considera como criterios:
- Claridad de la opini贸n expresada
- Especificidad respecto a la noticia
- Menci贸n de aspectos relevantes (ambiental, social, gobernanza o riesgo)
- Expresi贸n de preocupaciones o riesgos identificables

Respuesta del usuario: {respuesta}

Si la respuesta es vaga, demasiado breve o no menciona aspectos concretos, devuelve "False".
Si contiene una opini贸n sustancial con elementos analizables, devuelve "True".

Solo devuelve "True" o "False".
"""
prompt_evaluacion = PromptTemplate(template=plantilla_evaluacion, input_variables=["respuesta"])
cadena_evaluacion = LLMChain(llm=llm, prompt=prompt_evaluacion)

plantilla_reaccion = """
Reacci贸n del inversor: {reaccion}
Genera NICAMENTE una pregunta de seguimiento enfocada en profundizar en la opini贸n del inversor.  
Ejemplo:  
"驴Consideras que la existencia de mecanismos robustos de control interno y transparencia podr铆a mitigar tu preocupaci贸n por la gobernanza corporativa en esta empresa?"
"""
prompt_reaccion = PromptTemplate(template=plantilla_reaccion, input_variables=["reaccion"])
cadena_reaccion = LLMChain(llm=llm, prompt=prompt_reaccion)

plantilla_perfil = """
An谩lisis de reacciones: {analisis}
Genera un perfil detallado del inversor basado en sus reacciones, enfoc谩ndote en los pilares ESG (Ambiental, Social y Gobernanza) y su aversi贸n al riesgo. 
Asigna una puntuaci贸n de 0 a 100 para cada pilar ESG y para el riesgo, donde 0 indica ninguna preocupaci贸n y 100 m谩xima preocupaci贸n o aversi贸n.
Devuelve las 4 puntuaciones en formato: Ambiental: [puntuaci贸n], Social: [puntuaci贸n], Gobernanza: [puntuaci贸n], Riesgo: [puntuaci贸n]
"""
prompt_perfil = PromptTemplate(template=plantilla_perfil, input_variables=["analisis"])
cadena_perfil = LLMChain(llm=llm, prompt=prompt_perfil)

# Estados iniciales
if "historial" not in st.session_state:
    st.session_state.historial = []
    st.session_state.reacciones = []
    st.session_state.contador = 0
    st.session_state.mostrada_noticia = False
    st.session_state.pregunta_general_idx = 0
    st.session_state.preguntas_generales = []
    st.session_state.pregunta_pendiente = None

st.title("Chatbot de An谩lisis de Sentimiento")

# Mostrar historial
for mensaje in st.session_state.historial:
    with st.chat_message(mensaje["tipo"]):
        st.write(mensaje["contenido"])

# Preguntas generales antes de las noticias
if st.session_state.pregunta_general_idx < len(preguntas_inversor):
    pregunta_actual = preguntas_inversor[st.session_state.pregunta_general_idx]
    if not any(p["contenido"] == pregunta_actual for p in st.session_state.historial if p["tipo"] == "bot"):
        st.session_state.historial.append({"tipo": "bot", "contenido": pregunta_actual})
        with st.chat_message("bot", avatar=""):
            st.write(pregunta_actual)

    user_input = st.chat_input("Escribe tu respuesta aqu铆...")
    if user_input:
        st.session_state.historial.append({"tipo": "user", "contenido": user_input})
        st.session_state.reacciones.append(user_input)
        st.session_state.pregunta_general_idx += 1
        st.rerun()

# Funci贸n para procesar respuesta a noticia
def procesar_respuesta_valida(user_input):
    if st.session_state.pregunta_pendiente:
        del st.session_state.pregunta_pendiente
        st.session_state.reacciones.append(user_input)
        st.session_state.historial.append({"tipo": "user", "contenido": user_input})
        with st.chat_message("bot", avatar=""):
            st.write("Gracias por tu respuesta. Avanzando a la siguiente noticia...")
        st.session_state.historial.append({"tipo": "bot", "contenido": "Gracias por tu respuesta. Avanzando a la siguiente noticia..."})
        st.session_state.contador += 1
        st.session_state.mostrada_noticia = False
        st.rerun()
    else:
        evaluacion = cadena_evaluacion.run(respuesta=user_input).strip().lower()
        if evaluacion == "false":
            pregunta_ampliacion = cadena_reaccion.run(reaccion=user_input).strip()
            st.session_state.pregunta_pendiente = pregunta_ampliacion
            st.session_state.historial.append({"tipo": "bot", "contenido": pregunta_ampliacion})
            st.session_state.reacciones.append(user_input)
            with st.chat_message("bot", avatar=""):
                st.write(pregunta_ampliacion)
        else:
            st.session_state.reacciones.append(user_input)
            st.session_state.historial.append({"tipo": "user", "contenido": user_input})
            with st.chat_message("bot", avatar=""):
                st.write("Gracias por tu respuesta. Avanzando a la siguiente noticia...")
            st.session_state.historial.append({"tipo": "bot", "contenido": "Gracias por tu respuesta. Avanzando a la siguiente noticia..."})
            st.session_state.contador += 1
            st.session_state.mostrada_noticia = False
            st.rerun()

# L贸gica principal con noticias
elif st.session_state.contador < len(noticias):
    if not st.session_state.mostrada_noticia:
        noticia = noticias[st.session_state.contador]
        st.session_state.historial.append({"tipo": "bot", "contenido": f"驴Qu茅 opinas sobre esta noticia? {noticia}"})
        with st.chat_message("bot", avatar=""):
            st.write(f"驴Qu茅 opinas sobre esta noticia? {noticia}")
        st.session_state.mostrada_noticia = True

    user_input = st.chat_input("Escribe tu respuesta aqu铆...")
    if user_input:
        procesar_respuesta_valida(user_input)

# Final: perfil y gr谩fico
else:
    analisis_total = "\n".join(st.session_state.reacciones)
    perfil = cadena_perfil.run(analisis=analisis_total)
    with st.chat_message("bot", avatar=""):
        st.write(f"**Perfil del inversor:** {perfil}")
    st.session_state.historial.append({"tipo": "bot", "contenido": f"**Perfil del inversor:** {perfil}"})

    puntuaciones = {
        "Ambiental": int(re.search(r"Ambiental: (\d+)", perfil).group(1)),
        "Social": int(re.search(r"Social: (\d+)", perfil).group(1)),
        "Gobernanza": int(re.search(r"Gobernanza: (\d+)", perfil).group(1)),
        "Riesgo": int(re.search(r"Riesgo: (\d+)", perfil).group(1)),
    }

    fig, ax = plt.subplots()
    ax.bar(puntuaciones.keys(), puntuaciones.values())
    ax.set_ylabel("Puntuaci贸n (0-100)")
    ax.set_title("Perfil del Inversor")
    st.pyplot(fig)

    # Guardar en Google Sheets
    try:
        creds_json_str = st.secrets["gcp_service_account"]
        creds_json = json.loads(creds_json_str)
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_json, scope)
        client = gspread.authorize(creds)
        sheet = client.open('BBDD_RESPUESTAS').sheet1

        fila = st.session_state.reacciones + list(puntuaciones.values())
        sheet.append_row(fila)
        st.success("Datos guardados exitosamente en Google Sheets")
    except Exception as e:
        st.error(f"Error al guardar datos: {str(e)}")

# Foco autom谩tico al input
st.markdown("""
<script>
document.addEventListener('DOMContentLoaded', () => {
    const input = document.querySelector('.stChatInput textarea');
    if(input) input.focus();
});
</script>
""", unsafe_allow_html=True)
